#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
backtrace_scoped.py â€” program-aware COBOL var backtrace + PROC/JCL lineage (no SAS index)

Inputs (files in current working directory):
  - variables.csv        (from your COBOL indexer)
  - procs_index.csv      (from build_indexes.py)
  - jcl_index.csv        (from build_indexes.py)
  - ./copybook/**        (used only to whitelist copybook variables)

Output:
  - enhanced_backtrace.csv

Columns:
  copybook_variable, final_key_type, final_key,
  jcl_rows, proc_rows,
  producer_file, producer_step, producer_exec,
  input_files, sas_member,
  trace_path, cobol_file_hint
"""

import os, io, re, csv, glob
from collections import defaultdict, Counter
from heapq import heappush, heappop

# ---------------- configuration ----------------
BASE = os.getcwd()
CPY_DIR   = os.path.join(BASE, "copybook")
CSV_VARS  = os.path.join(BASE, "variables.csv")
CSV_PROCS = os.path.join(BASE, "procs_index.csv")
CSV_JCL   = os.path.join(BASE, "jcl_index.csv")
CSV_OUT   = os.path.join(BASE, "enhanced_backtrace.csv")

# report only copybook variables (True recommended)
INCLUDE_ONLY_COPYBOOK = True

# allow a source hop to another scope when the source name is unique
ALLOW_CROSS_SCOPE_IF_UNIQUE = True

# prefer the final ASSIGN ddname over the raw DD name (usually what you want)
PREFER_ASSIGN_OVER_DD = True

# search limits
MAX_DEPTH = 2000
MAX_PATHS_PER_VAR = 50

# set to a specific copybook variable to narrow the run (optional)
QUERY = ""   # e.g. "ALS-BOOKING-DATE"

IDENT = r"[A-Z0-9][A-Z0-9\-]*"
RE_ITEM = re.compile(rf"^\s*(\d{{2}})\s+({IDENT})\b", re.I)
RE_88   = re.compile(r"^\s*88\b", re.I)

def norm(s): 
    return re.sub(r"\s+","",s.upper()) if isinstance(s,str) else s

def read_text(p):
    with io.open(p,"r",encoding="utf-8",errors="ignore") as f:
        return f.read()

def split_list(s):
    return [norm(x) for x in (s or "").split(";") if x and x.strip()]

def is_pseudo(n):
    return isinstance(n,str) and (n.startswith("DD:") or n.startswith("ASSIGN:"))

# ---------------- copybook allow-list ----------------
def copybook_names(copy_dir):
    allow=set()
    for path in glob.glob(os.path.join(copy_dir,"**/*"), recursive=True):
        if not os.path.isfile(path): continue
        if not path.upper().endswith((".CPY",".CPB",".CBL",".COB",".TXT",".INC",".COPY",".CP")):
            continue
        for raw in read_text(path).splitlines():
            if not raw.strip() or RE_88.match(raw): 
                continue
            m=RE_ITEM.match(raw)
            if m:
                nm=norm(m.group(2))
                if nm!="FILLER":
                    allow.add(nm)
    return allow

# ---------------- graph from variables.csv (scoped by root record) ----------------
def load_vars_scoped(csv_path):
    rows_present = {}
    parent_of_name = {}
    from_dd_of_name = defaultdict(set)
    assign_of_name  = defaultdict(set)
    sources_of_name = defaultdict(set)
    origin_file_of_name = {}

    with io.open(csv_path, newline="", encoding="utf-8") as f:
        r=csv.DictReader(f)
        lower={k.lower():k for k in r.fieldnames}
        def get(row,key,default=""):
            real = lower.get(key.lower(), key)
            return row.get(real, default)

        for row in r:
            v=norm(get(row,"variable"))
            if not v: continue
            rows_present[v]=True
            origin_file_of_name[v]=get(row,"origin_file","") or ""
            p=norm(get(row,"parent_record"))
            if p: parent_of_name[v]=p
            for dd in split_list(get(row,"from_dd","")):
                from_dd_of_name[v].add(dd)
            for at in split_list(get(row,"assign_target","")):
                # sanitize any bad tokens (e.g., LONCTXFILESTATUS...) to first ident
                m = re.match(r"[A-Z0-9$#@-]+", at)
                if m: assign_of_name[v].add(m.group(0))
            ds = get(row,"direct_sources") or get(row,"source_fields")
            for s in split_list(ds):
                sources_of_name[v].add(s)

    def root_for(name):
        seen=set(); cur=name
        while True:
            if cur in seen: break
            seen.add(cur)
            p=parent_of_name.get(cur)
            if not p: break
            cur=p
        return cur

    root_of_name={n: (root_for(n) or (origin_file_of_name.get(n,"") or "GLOBAL")) for n in rows_present.keys()}

    def node_id(root,name): return ("VAR",root,name)

    nodes=set()
    by_scope_name={}
    by_name=defaultdict(set)
    origin_for_node={}
    root_members=defaultdict(set)

    for name in rows_present.keys():
        root=root_of_name[name]
        nid=node_id(root,name)
        nodes.add(nid)
        by_scope_name[(root,name)] = nid
        by_name[name].add(nid)
        origin_for_node[nid] = origin_file_of_name.get(name,"")
        root_members[root].add(name)

    parent_edge={}
    for name,parent in parent_of_name.items():
        r=root_of_name[name]
        child=by_scope_name.get((r,name))
        par  =by_scope_name.get((r,parent))
        if child and par:
            parent_edge[child]=par

    sources_edges=defaultdict(set)
    for name, srcs in sources_of_name.items():
        r=root_of_name[name]
        frm=by_scope_name.get((r,name))
        if not frm: continue
        for s in srcs:
            same=by_scope_name.get((r,s))
            if same:
                sources_edges[frm].add(same)
            else:
                cands=list(by_name.get(s,[]))
                if ALLOW_CROSS_SCOPE_IF_UNIQUE and len(cands)==1:
                    sources_edges[frm].add(cands[0])

    from_dd_node=defaultdict(set)
    assign_node=defaultdict(set)
    for name,dds in from_dd_of_name.items():
        r=root_of_name[name]
        frm=by_scope_name.get((r,name))
        if not frm: continue
        for dd in dds:
            # defensive clean on dd
            m = re.match(r"[A-Z0-9$#@-]+", dd)
            if m: from_dd_node[frm].add(m.group(0))
    for name,ats in assign_of_name.items():
        r=root_of_name[name]
        frm=by_scope_name.get((r,name))
        if not frm: continue
        for at in ats:
            assign_node[frm].add(at)

    return {
        "nodes": nodes,
        "by_scope_name": by_scope_name,
        "by_name": by_name,
        "origin_for": origin_for_node,
        "parent_of": parent_edge,
        "sources_of": sources_edges,
        "from_dd_of": from_dd_node,
        "assign_of": assign_node,
        "root_of_name": root_of_name,
        "root_members": root_members
    }

def neighbors(G, node):
    parent_of=G["parent_of"]
    sources_of=G["sources_of"]
    from_dd_of=G["from_dd_of"]
    assign_of=G["assign_of"]

    if is_pseudo(node):
        # DD:<dd> -> ASSIGN:<dd-assign> (if present on any node with that DD)
        if node.startswith("DD:"):
            dd=node[3:]
            hops=set()
            for n,dds in from_dd_of.items():
                if dd in dds:
                    for at in assign_of.get(n,set()):
                        if at: hops.add(f"ASSIGN:{at}")
            return hops
        return set()

    hops=set()
    p=parent_of.get(node)
    if p: hops.add(p)
    hops |= sources_of.get(node,set())
    for dd in from_dd_of.get(node,set()):
        hops.add(f"DD:{dd}")
    for at in assign_of.get(node,set()):
        hops.add(f"ASSIGN:{at}")
    return hops

def rank_path(path):
    tail = path[-1]
    # prioritize ASSIGN (best), then DD, then plain variable
    if isinstance(tail,str) and tail.startswith("ASSIGN:"):
        cls=0
    elif isinstance(tail,str) and tail.startswith("DD:"):
        cls=1
    else:
        cls=2
    return (cls, len(path))

def all_leaf_paths_ranked(G, start_name, max_depth=MAX_DEPTH, cap=MAX_PATHS_PER_VAR):
    root=G["root_of_name"].get(start_name)
    if not root: return []
    start=G["by_scope_name"].get((root,start_name))
    if not start: return []
    heap=[]; heappush(heap,(rank_path([start]),[start])); leaves=[]; seen=set()
    while heap and len(leaves)<cap:
        _,path=heappop(heap)
        cur=path[-1]
        nxts=neighbors(G,cur)
        if not nxts or len(path)>max_depth:
            leaves.append(path); continue
        for nxt in sorted(nxts, key=lambda x: (isinstance(x,tuple), str(x))):
            e=(cur,nxt)
            if e in seen: 
                continue
            seen.add(e)
            if isinstance(nxt,tuple) and nxt in path:
                leaves.append(path); continue
            heappush(heap,(rank_path(path+[nxt]), path+[nxt]))
    return leaves

# ---------------- read indexes ----------------
def load_csv_rows(path):
    if not os.path.exists(path): return []
    with io.open(path, newline="", encoding="utf-8") as f:
        return list(csv.DictReader(f))

def rows_to_str(rows, cols):
    if not rows: return ""
    return " || ".join("|".join(str(r.get(c,"")) for c in cols) for r in rows)

def program_name_from_file(path: str) -> str:
    if not path: return ""
    base=os.path.basename(path)
    m=re.match(r"([A-Z0-9$#@]+)", base.upper())
    return m.group(1) if m else base.upper()

def filter_rows_to_program(rows, prog):
    if not prog: return rows
    filt=[r for r in rows if (r.get("exec_pgm","") or "").upper()==prog.upper()]
    return filt or rows  # fall back if nothing matches

def same_dsn_or_tail(a: dict, b: dict) -> bool:
    da=(a.get("dsn","") or "").upper()
    db=(b.get("dsn","") or "").upper()
    if da and db and da==db:
        return True
    ta=(a.get("dsn_tail","") or "").upper()
    tb=(b.get("dsn_tail","") or "").upper()
    return (ta and tb and ta==tb)

SYS_DDS = {"SYSOUT","SYSPRINT","SYSUDUMP","SYSIN","SYSABOUT"}

def parse_sas_member_from_raw(raw: str) -> str:
    # e.g., DSN=TD.SASLIB(ALSLOND) -> ALSLOND
    if not raw: return ""
    m=re.search(r"\bDSN\s*=\s*[^()]*\(\s*([A-Z0-9_]+)\s*\)", raw.upper())
    return m.group(1) if m else ""

def find_producer_and_inputs(all_proc_rows, all_jcl_rows, selected_row):
    """
    Given a selected DD row (from current program), find a producer step for the same dataset
    (exact DSN or DSN tail match), then list that step's input DD=DSN pairs and SAS SYSIN member.
    """
    if not selected_row: return None, [], ""
    related = [r for r in all_proc_rows if same_dsn_or_tail(r, selected_row)]
    related += [r for r in all_jcl_rows if same_dsn_or_tail(r, selected_row)]

    def is_other_step(r):
        return not (r.get("file")==selected_row.get("file") and r.get("step")==selected_row.get("step"))

    candidates = [r for r in related if is_other_step(r)]
    # prefer production-like creators (SAS or SORT)
    pref_execs={"SAS","SORT","ICEMAN","DFSORT"}
    producer=None
    for r in candidates:
        if (r.get("exec_pgm","") or "").upper() in pref_execs:
            producer=r; break
    if not producer and candidates:
        producer=candidates[0]
    if not producer:
        return None, [], ""

    p_file, p_step = producer.get("file",""), producer.get("step","")
    out_dd = (producer.get("ddname","") or "").upper()

    same_step = [r for r in all_proc_rows if r.get("file","")==p_file and r.get("step","")==p_step]
    same_step += [r for r in all_jcl_rows  if r.get("file","")==p_file and r.get("step","")==p_step]

    inputs=[]; sas_member=""
    for r in same_step:
        dd=(r.get("ddname","") or "").upper()
        if dd == out_dd:
            continue
        if dd in SYS_DDS:
            if dd=="SYSIN" and r.get("raw",""):
                sas_member = sas_member or parse_sas_member_from_raw(r.get("raw",""))
            continue
        val = r.get("dsn") or r.get("dsn_tail")
        if val:
            inputs.append(f"{dd}={val}")
    return producer, inputs, sas_member

# ---------------- enhancement per path ----------------
def disp(n, dupes=None):
    # Show just the variable name (third element) for tuple nodes
    if isinstance(n,tuple):
        return n[2]
    return n

def enhance_one(G, path, lookups, dupes, all_proc_rows, all_jcl_rows):
    by_ddname_proc, by_ddname_jcl = lookups
    origin_for = G["origin_for"]

    start_name = disp(path[0], dupes)
    shows = [disp(n, dupes) for n in path]

    cob_file=""; prog_name=""
    for n in path:
        if isinstance(n,tuple):
            cob_file = origin_for.get(n,"")
            if cob_file:
                prog_name = program_name_from_file(cob_file)
                break

    assigns=[x[7:] for x in shows if isinstance(x,str) and x.startswith("ASSIGN:")]
    dds    =[x[3:] for x in shows if isinstance(x,str) and x.startswith("DD:")]

    if PREFER_ASSIGN_OVER_DD:
        final_key_type = "ASSIGN" if assigns else ("DD" if dds else "")
        final_key = assigns[-1] if assigns else (dds[-1] if dds else "")
    else:
        final_key_type = "DD" if dds else ("ASSIGN" if assigns else "")
        final_key = dds[-1] if dds else (assigns[-1] if assigns else "")

    key = norm(final_key)

    # find PROC/JCL rows by DD name, filter to this COBOL program if possible
    proc_rows_all = by_ddname_proc.get(key, [])
    jcl_rows_all  = by_ddname_jcl.get(key, [])
    proc_rows = filter_rows_to_program(proc_rows_all, prog_name)
    jcl_rows  = filter_rows_to_program(jcl_rows_all,  prog_name)
    if not proc_rows and proc_rows_all: proc_rows = proc_rows_all
    if not jcl_rows and jcl_rows_all:   jcl_rows = jcl_rows_all

    # pick one matched row (prefer PROC), then walk to producer step
    chosen = (proc_rows[0] if proc_rows else (jcl_rows[0] if jcl_rows else None))
    producer_file = producer_step = producer_exec = ""
    input_files=[]; sas_member=""
    if chosen:
        prod, inputs, sas_mem = find_producer_and_inputs(all_proc_rows, all_jcl_rows, chosen)
        if prod:
            producer_file = prod.get("file","")
            producer_step = prod.get("step","")
            producer_exec = prod.get("exec","")
            input_files = inputs
            sas_member = sas_mem

    return {
        "copybook_variable": start_name,
        "final_key_type": final_key_type,
        "final_key": final_key,
        "jcl_rows": rows_to_str(jcl_rows,  ["file","step","exec","exec_pgm","ddname","dsn"]),
        "proc_rows": rows_to_str(proc_rows, ["file","step","exec","exec_pgm","ddname","dsn"]),
        "producer_file": producer_file,
        "producer_step": producer_step,
        "producer_exec": producer_exec,
        "input_files": "; ".join(input_files),
        "sas_member": sas_member,
        "trace_path": " <- ".join(shows),
        "cobol_file_hint": cob_file
    }

# ---------------- main ----------------
def build_lookups(procs_rows, jcl_rows):
    def N(x): return norm(x or "")
    by_ddname_proc=defaultdict(list)
    by_ddname_jcl=defaultdict(list)
    for r in procs_rows: by_ddname_proc[N(r.get("ddname"))].append(r)
    for r in jcl_rows:  by_ddname_jcl[N(r.get("ddname"))].append(r)
    return by_ddname_proc, by_ddname_jcl

def main():
    # copybook allow-list (optional but recommended)
    allow = copybook_names(CPY_DIR) if INCLUDE_ONLY_COPYBOOK else None

    if not os.path.exists(CSV_VARS):
        print("variables.csv not found"); return
    G = load_vars_scoped(CSV_VARS)

    # detect duplicate variable names across scopes to show clean labels
    name_counts = Counter()
    for _, _, name in G["nodes"]:
        name_counts[name]+=1
    dupes = {n for n,c in name_counts.items() if c>1}

    vars_in_csv = set(G["root_of_name"].keys())
    targets = sorted(n for n in vars_in_csv if (not INCLUDE_ONLY_COPYBOOK or (allow and n in allow)))
    if QUERY:
        q=norm(QUERY)
        targets=[q] if q in targets else []

    procs = load_csv_rows(CSV_PROCS)
    jcls  = load_csv_rows(CSV_JCL)
    lookups = build_lookups(procs, jcls)

    out=[]; seen=set()
    for name in targets:
        for p in all_leaf_paths_ranked(G, name):
            row = enhance_one(G, p, lookups, dupes, procs, jcls)
            key=(row["copybook_variable"], row["final_key_type"], row["final_key"], row["trace_path"])
            if key in seen: 
                continue
            seen.add(key)
            out.append(row)

    with io.open(CSV_OUT,"w",newline="",encoding="utf-8") as f:
        w=csv.DictWriter(f, fieldnames=[
            "copybook_variable","final_key_type","final_key",
            "jcl_rows","proc_rows",
            "producer_file","producer_step","producer_exec",
            "input_files","sas_member",
            "trace_path","cobol_file_hint"
        ])
        w.writeheader()
        for r in out:
            w.writerow(r)

    print(f"Wrote {CSV_OUT} (rows={len(out)})")

if __name__=="__main__":
    main()
